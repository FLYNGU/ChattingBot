{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ner-torch模型功能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:14:21.885848Z",
     "start_time": "2022-07-03T03:14:21.793852Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\envs\\pytorch\\lib\\site-packages\\torchcrf\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorCompare.cpp:328.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['李白', 'author', [0, 1]], ['杜甫', 'author', [9, 10]]]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F # pytorch 激活函数的类\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torchcrf import CRF\n",
    "\n",
    "\n",
    "# 构建基于bilstm+crf实现ner\n",
    "class bilstm_crf(nn.Module):\n",
    "    def __init__(self, parameter):\n",
    "        super(bilstm_crf, self).__init__()\n",
    "        vocab_size = parameter['vocab_size']\n",
    "        embedding_dim = parameter['d_model']\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        hidden_size = parameter['hid_dim']\n",
    "        num_layers = parameter['n_layers']\n",
    "        dropout = parameter['dropout']\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, bidirectional=True, batch_first=True, dropout=dropout)\n",
    "\n",
    "        output_size = parameter['num_tags']\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "        \n",
    "        self.crf = CRF(output_size,batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out,(h, c)= self.lstm(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# 此处是加载对应的模型和配置文件\n",
    "def load_model(mode_path):\n",
    "    parameter = pk.load(open(mode_path+'parameter.pkl','rb'))\n",
    "    parameter['device'] = torch.device('cpu')\n",
    "    # 因为bert模型需要加载他对应的config文件，因此此处进行了一定的区分\n",
    "    model = bilstm_crf(parameter).to(parameter['device'])\n",
    "    model.load_state_dict(torch.load(model_path+'bilstm_crf.h5',map_location='cpu'))\n",
    "    model.eval() \n",
    "    return model,parameter\n",
    "\n",
    "def keyword_predict(input):\n",
    "    def list2torch(ins):\n",
    "        return torch.from_numpy(np.array(ins))\n",
    "    def seq2id(seq, vocab):\n",
    "        sentence_id = []\n",
    "        for word in seq:\n",
    "            if word not in vocab:\n",
    "                word = '<UNK>'\n",
    "            sentence_id.append(vocab[word])\n",
    "        return sentence_id\n",
    "    input = list(input)\n",
    "    ind2key = dict(zip(parameter['tag2label'].values(),parameter['tag2label'].keys()))\n",
    "    input_id = seq2id(input,parameter['vocab'])#itemgetter(*input)(parameter['word2ind'])\n",
    "    predict = model.crf.decode(model(list2torch([input_id]).long().to(parameter['device'])))[0]\n",
    "    predict = itemgetter(*predict)(ind2key)\n",
    "    keys_list = []\n",
    "    for ind,i in enumerate(predict):\n",
    "        if i == 'O':\n",
    "            continue\n",
    "        if i[0] == 'S':\n",
    "            if not(len(keys_list) == 0 or keys_list[-1][-1]):\n",
    "                del keys_list[-1]\n",
    "            keys_list.append([input[ind],[i],[ind],True])\n",
    "            continue\n",
    "        if i[0] == 'B':\n",
    "            if not(len(keys_list) == 0 or keys_list[-1][-1]):\n",
    "                del keys_list[-1]\n",
    "            keys_list.append([input[ind],[i],[ind],False])\n",
    "            continue\n",
    "        if i[0] == 'I':\n",
    "            if len(keys_list) > 0 and not keys_list[-1][-1] and \\\n",
    "            keys_list[-1][1][0].split('-')[1] == i.split('-')[1]:\n",
    "                keys_list[-1][0] += input[ind]\n",
    "                keys_list[-1][1] += [i]\n",
    "                keys_list[-1][2] += [ind]\n",
    "            else:\n",
    "                if len(keys_list) > 0:\n",
    "                    del keys_list[-1]\n",
    "            continue\n",
    "        if i[0] == 'E':\n",
    "            if len(keys_list) > 0 and not keys_list[-1][-1] and \\\n",
    "            keys_list[-1][1][0].split('-')[1] == i.split('-')[1]:\n",
    "                keys_list[-1][0] += input[ind]\n",
    "                keys_list[-1][1] += [i]\n",
    "                keys_list[-1][2] += [ind]\n",
    "                keys_list[-1][3] = True\n",
    "            else:\n",
    "                if len(keys_list) > 0:\n",
    "                    del keys_list[-1]\n",
    "            continue\n",
    "    keys_list = [[i[0],i[1][0].split('-')[1],i[2]] for i in keys_list]\n",
    "    return keys_list\n",
    "\n",
    "model_path = 'model/ner/'\n",
    "model,parameter = load_model(model_path)\n",
    "\n",
    "keyword_predict('李白写过哪些诗句，杜甫写过哪些诗句')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T08:01:20.437504Z",
     "start_time": "2021-11-21T08:01:20.419524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"match p = (n:author)-[]->(m:introduce) where n.name = '李白' return m.name\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity = ['李白', 'author', [0, 1]]\n",
    "\"match p = (n:%s)-[]->(m:introduce) where n.name = '%s' return m.name\"%(entity[1],entity[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:15:58.616365Z",
     "start_time": "2022-07-03T03:15:58.599357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('author',\n",
       " '写',\n",
       " '过',\n",
       " '哪',\n",
       " '些',\n",
       " '诗',\n",
       " '句',\n",
       " '，',\n",
       " 'author',\n",
       " '写',\n",
       " '过',\n",
       " '哪',\n",
       " '些',\n",
       " '诗',\n",
       " '句')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基于ner重建后的提问\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "def takelong(ins):\n",
    "    return len(ins[0])\n",
    "\n",
    "def rebuildiins(ins,entity_list):\n",
    "    new_ins = {}\n",
    "    left_ind = set(range(len(ins)))\n",
    "    for i in entity_list:\n",
    "        left_ind -= set(range(i[-1][0],i[-1][-1]+1))\n",
    "        new_ins[i[-1][0]] = i[1]\n",
    "    for i in left_ind:\n",
    "        new_ins[i] = ins[i]\n",
    "    new_id = list(new_ins.keys())\n",
    "    new_id.sort()\n",
    "    return itemgetter(*new_id)(new_ins)\n",
    "\n",
    "question = '李白写过哪些诗句，杜甫写过哪些诗句'\n",
    "entity_list = [['李白', 'author', [0, 1]], ['杜甫', 'author', [9, 10]]]\n",
    "entity_list.sort(key = takelong)\n",
    "entity_list = entity_list[::-1]\n",
    "new_question = rebuildiins(question,entity_list)\n",
    "new_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 意图识别功能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:19:23.507014Z",
     "start_time": "2022-07-03T03:19:23.427982Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F # pytorch 激活函数的类\n",
    "from torch import nn,optim # 构建模型和优化器\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict\n",
    "\n",
    "# 构建分类模型\n",
    "class TextRNN(nn.Module):\n",
    "    def __init__(self, parameter):\n",
    "        super(TextRNN, self).__init__()\n",
    "        embedding_dim = parameter['embedding_dim']\n",
    "        hidden_size = parameter['hidden_size']\n",
    "        output_size = parameter['output_size']\n",
    "        num_layers = parameter['num_layers']\n",
    "        dropout = parameter['dropout']\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, bidirectional=True, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out,(h, c)= self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "def load_model(path):\n",
    "    parameter = pk.load(open(path,'rb'))\n",
    "    parameter['dropout'] = 0\n",
    "    model = TextRNN(parameter).to(parameter['cuda'])\n",
    "    model.load_state_dict(torch.load(parameter['model_path']+'model-rnn.h5'))\n",
    "    return parameter,model\n",
    "\n",
    "def batch_predict(chars,parameter):\n",
    "        max_len = 0\n",
    "        batch_x = []\n",
    "        for iters in range(len(chars)):\n",
    "            for i in range(len(chars[iters])):\n",
    "                if chars[iters][i] not in parameter['char2ind']:\n",
    "                    chars[iters][i] = '<unk>'\n",
    "            batch_ids = itemgetter(*chars[iters])(parameter['char2ind'])\n",
    "            try:\n",
    "                batch_ids = list(batch_ids)\n",
    "            except:\n",
    "                batch_ids = [batch_ids,0]\n",
    "            if len(batch_ids) > max_len:\n",
    "                max_len = len(batch_ids)\n",
    "            batch_x.append(batch_ids)\n",
    "        batch_x = [np.array(list(itemgetter(*x_ids)(parameter['ind2embeding']))+[parameter['ind2embeding'][0]]*(max_len-len(x_ids))) for x_ids in batch_x]\n",
    "        device = parameter['cuda']\n",
    "        return torch.from_numpy(np.array(batch_x)).to(device)\n",
    "    \n",
    "def predict(ins,model,parameter):\n",
    "    seqs = batch_predict(ins,parameter)\n",
    "    res = model(seqs)\n",
    "    predicted_prob,predicted_index = torch.max(F.softmax(res, 1), 1)\n",
    "    res = predicted_index.cpu().numpy()\n",
    "    return res\n",
    "\n",
    "\n",
    "intent0_parameter,intent0_model = load_model('model/intent0/parameter.pkl')\n",
    "intent1_parameter,intent1_model = load_model('model/intent1/parameter.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent1_parameter['cuda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:16:21.400523Z",
     "start_time": "2022-07-03T03:16:21.390523Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['老', '师', 'km1', '有', '哪', '些', '重', '要', '的', '课'],\n",
       " ['说', '你', '的', '工', '作'],\n",
       " ['唱', '歌', '吧'],\n",
       " 0,\n",
       " 1,\n",
       " 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pk\n",
    "x,y = pk.load(open('data/data-intent0.pkl','rb'))\n",
    "x[1],x[300],x[500],y[1],y[300],y[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:16:22.900128Z",
     "start_time": "2022-07-03T03:16:22.883129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict([['老', '师', 'km1', '有', '哪', '些', '重', '要', '的', '课'],\n",
    "        ['说', '你', '的', '工', '作'],\n",
    "         ['唱', '歌', '吧'],\n",
    "        ],intent0_model,intent0_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:16:29.228055Z",
     "start_time": "2022-07-03T03:16:29.074077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['老', '师', 'km1', '有', '哪', '些', '重', '要', '的', '课'],\n",
       " ['老', '师', 'km1', '有', '哪', '些', '重', '要', '的', '知', '识', '点'],\n",
       " ['老', '师', 'km2', '有', '哪', '些', '重', '要', '的', '例', '题', '需', '要', '掌', '握'],\n",
       " 0,\n",
       " 1,\n",
       " 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pk\n",
    "x,y,_,_ = pk.load(open('data/data-intent1-ner.pkl','rb'))\n",
    "x[1],x[20],x[100],y[1],y[20],y[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-03T03:16:31.429352Z",
     "start_time": "2022-07-03T03:16:31.409352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict([['老', '师', 'km1', '有', '哪', '些', '重', '要', '的', '课'],\n",
    " ['老', '师', 'km1', '有', '哪', '些', '重', '要', '的', '知', '识', '点'],\n",
    " ['老', '师', 'km2', '有', '哪', '些', '重', '要', '的', '例', '题', '需', '要', '掌', '握'],\n",
    "        ],intent1_model,intent1_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
